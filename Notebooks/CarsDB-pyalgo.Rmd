---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.2.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Populate DB with python-code's results
It builds an an [HDF5 file](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-hdf5) 
with the *outputs* (`oprop`, `cycle`) from this *wltp* library.

```{python tags=c("parameters")}
### Cell tagged as `parameters` for *papermill*.
#
skip_h5_write = False
del_h5_on_start = False  # overriden by `skip_h5_write=True`
```

```{python}
## To autoreload codein python files here.
# %load_ext autoreload
# %autoreload 2

## Add %%black at the top of a cell, and re-evaluate it, 
# to format it before git-commits, and ease diffs.
# %load_ext blackcellmagic
```

```{python}
from typing import Tuple, Union, Sequence as Seq
import io
import sys
import logging
from pathlib import Path, PurePosixPath as P

import numpy as np
import pandas as pd
from wltp.experiment import Experiment
import wltp
from wltp import utils as wutils, io as wio

## Add tests/ into `sys.path` to import `vehdb` module.
#
proj_dir = str(Path(wltp.__file__).parents[1] / "tests")
if proj_dir not in sys.path:
    sys.path.insert(0, proj_dir)

import vehdb

log = logging.getLogger('CarsDB-pyalgo.ipynb')
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s|%(levelname)4.4s|%(module)s:[%(funcName)s]:\n  +--> %(message)s', 
    datefmt='%Y-%m-%d,%H:%M:%S',
)
```

```{python}
## DEFINITIONS
#
inp_h5fname = 'VehData/WltpGS-msaccess.h5'
out_h5fname = 'VehData/WltpGS-pyalgo.h5'
# Test cars delivered by Heinz to ank on 4 Jun 2019
c_n, c_p, c_n_norm, c_p_norm = 'n', 'Pwot', 'n_norm', 'p_norm'
```

```{python}
## UNCOMMENT next command & run to DELETE the db-file, and rebuild it.
if not skip_h5_write and del_h5_on_start:
    !rm -f {out_h5fname}
```

```{python}
vehdb.print_nodes(out_h5fname)
```

```{python}
# %pdb off
```

```{python}
def store_python_results(
    inph5,
    outh5,
    vehile_nums: Seq[int] = None,
    props_group_suffix="oprop",
    cycle_group_suffix="cycle",
    no_write=False,
):
    """
    RUN PYTHON on cars that have HeinzDB results in /vechicles/v123/out1
    
    and build:
    
        vehicles/
            +--v001/
            |   +--oprop      ADD: (series) scalars generated by python-algo
            |   +--cycle      ADD: (df) cycle-run generated by python-alog
            +...
            
    """

    def run_vehicles_with_pythons(h5db):
        veh_nums = vehdb.all_vehnums(h5db) if vehile_nums is None else vehile_nums
        for vehnum in veh_nums:
            log.info("Processing veh(v%0.3i)...", vehnum)
            try:
                yield vehnum, vehdb.run_pyalgo_on_Heinz_vehicle(inph5, vehnum)
            except Exception as ex:
                log.error("V%0.3i failed: %s", vehnum, ex)
                raise ex

    def store_vehicles(h5db, vehnum, oprops, cycle_run):
        if no_write:
            return

        g = vehdb.vehnode(vehnum, props_group_suffix)
        h5db.put(g, pd.DataFrame({k: [v] for k, v in oprops.items()}, index=[vehnum]))
        vehdb.provenir_h5node(h5db, g, title="Pyalgo generated")

        g = vehdb.vehnode(vehnum, cycle_group_suffix)
        h5db.put(g, cycle_run)
        vehdb.provenir_h5node(h5db, g, title="Pyalgo generated")

    for vehnum, (oprops, cycle_run) in vehdb.do_h5(inph5, run_vehicles_with_pythons):
        vehdb.do_h5(outh5, store_vehicles, vehnum, oprops, cycle_run)


with vehdb.openh5(inp_h5fname) as inph5, vehdb.openh5(out_h5fname) as outh5:
    store_python_results(inph5, outh5, no_write=skip_h5_write)#, vehile_nums=[59])
```

```{python}
vehdb.print_nodes(out_h5fname)
```

```{python}
# %%time
if not skip_h5_write:
    ## COMPRESS x8 HDF5: 143Mb-->18Mb in ~6s.
    #
    !ls -lh {out_h5fname}
    !ptrepack  {out_h5fname}  --complevel=9 --complib=blosc:blosclz -o {out_h5fname}.tmp
    !mv  {out_h5fname}.tmp {out_h5fname}
    !ls -lh {out_h5fname}
```
